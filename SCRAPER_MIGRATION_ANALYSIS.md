# ğŸ•·ï¸ ANÃLISIS DE MIGRACIÃ“N DEL SCRAPER

**Fecha:** 11 de Septiembre, 2025  
**Estado:** AnÃ¡lisis Completo  
**Objetivo:** Migrar scraper legacy a nueva arquitectura modular

---

## ğŸ“‹ ESTRUCTURA ACTUAL (Legacy)

### ğŸ—‚ï¸ **Arquitectura Existente**
```
services/scraper/
â”œâ”€â”€ edeka_scraper/                 # Package principal Scrapy
â”‚   â”œâ”€â”€ spiders/
â”‚   â”‚   â””â”€â”€ edeka_spider.py        # Spider principal de Edeka
â”‚   â”œâ”€â”€ items.py                   # DefiniciÃ³n de Items Scrapy
â”‚   â”œâ”€â”€ pipelines.py               # Pipeline SQLAlchemy (legacy)
â”‚   â”œâ”€â”€ settings.py                # ConfiguraciÃ³n Scrapy
â”‚   â””â”€â”€ middlewares.py             # Middlewares (no analizados aÃºn)
â”œâ”€â”€ database/                      # Base de datos legacy (obsoleta)
â”œâ”€â”€ main.py                        # Entry point
â””â”€â”€ scrapy.cfg                     # ConfiguraciÃ³n Scrapy
```

---

## ğŸ” ANÃLISIS DETALLADO DE COMPONENTES

### ğŸ“Š **1. Items Actuales (items.py)**

**Campos existentes en `EdekaProductItem`:**
```python
# InformaciÃ³n relacional
store_name           â†’ Store.name
category_path        â†’ Category hierarchy mapping
# manufacturer_name  â†’ Manufacturer.name (comentado)

# InformaciÃ³n del producto
name                 â†’ Product.name
price_amount         â†’ Product.price_amount  
price_currency       â†’ Product.price_currency
sku                  â†’ Product.sku

# URLs
product_url          â†’ Product.product_url
image_url            â†’ Product.image_url

# Contenido
description          â†’ Product.description

# Precio base
base_price_text      â†’ Necesita parsing â†’ Product.base_price_*

# Metadatos
scraped_at           â†’ Product.scraped_at
```

### ğŸ•·ï¸ **2. Spider Actual (edeka_spider.py)**

**Funcionalidades implementadas:**
- âœ… **Sitemap parsing** - Navega sitemaps de productos
- âœ… **Product extraction** - Extrae datos de pÃ¡ginas individuales
- âœ… **Category hierarchy** - Maneja breadcrumbs de categorÃ­as
- âœ… **Price parsing** - Extrae precios con regex
- âœ… **Image URLs** - Construye URLs completas de imÃ¡genes
- âœ… **Metadata** - Timestamps y informaciÃ³n de scraping

**Limitaciones identificadas:**
- ğŸ”¶ **Hardcoded lÃ­mite** - Solo 5 productos por sitemap (testing)
- ğŸ”¶ **Manufacturer extraction** - No implementado
- ğŸ”¶ **Price parsing bÃ¡sico** - Solo precio principal, no base price completo
- ğŸ”¶ **Error handling limitado** - Manejo de errores bÃ¡sico

### ğŸ”§ **3. Pipeline Actual (pipelines.py)**

**Funcionalidades:**
- âœ… **SQLAlchemy integration** - Usa modelos legacy
- âœ… **Store management** - Get or create stores
- âœ… **Category hierarchy** - Crea categorÃ­as anidadas
- âœ… **Product UPSERT** - Actualiza productos existentes

**Problemas identificados:**
- âŒ **Base de datos incorrecta** - Usa modelos legacy obsoletos
- âŒ **Imports rotos** - `from database import models` (no existe)
- âŒ **Session management** - No usa nuevos repositorios
- âŒ **Data transformation** - No procesa base_price_text correctamente
- âŒ **Error handling** - Rollback bÃ¡sico sin logging

### âš™ï¸ **4. ConfiguraciÃ³n (settings.py)**

**ConfiguraciÃ³n actual:**
- âœ… **Respectful crawling** - ROBOTSTXT_OBEY = True
- âœ… **Rate limiting** - DOWNLOAD_DELAY = 20 (cumple requerimientos)
- âœ… **Conservative concurrency** - 1 request por dominio
- âš ï¸ **Database config** - Variables de entorno configuradas pero legacy

---

## ğŸ“ˆ MAPEO DE DATOS: Legacy â†’ New Models

### ğŸ”„ **Transformaciones Requeridas**

| Campo Legacy | Nuevo Campo | TransformaciÃ³n Necesaria |
|-------------|-------------|--------------------------|
| `store_name` | `Store.name` | âœ… Directo |
| `category_path` | `Category` hierarchy | ğŸ”§ Crear/mapear jerarquÃ­a |
| `name` | `Product.name` | âœ… Directo |
| `price_amount` | `Product.price_amount` | âœ… Directo |
| `price_currency` | `Product.price_currency` | âœ… Directo |
| `sku` | `Product.sku` | âœ… Directo |
| `product_url` | `Product.product_url` | âœ… Directo |
| `image_url` | `Product.image_url` | âœ… Directo |
| `description` | `Product.description` | âœ… Directo |
| `base_price_text` | `Product.base_price_*` | ğŸ”§ **Parser necesario** |
| `scraped_at` | `Product.scraped_at` | âœ… Directo |

### ğŸ†• **Campos Nuevos a Implementar**

**Campos faltantes en scraper actual:**
```python
# InformaciÃ³n de precios detallada
base_price_amount     # Extraer de base_price_text
base_price_unit       # Extraer de base_price_text  
base_price_quantity   # Extraer de base_price_text

# InformaciÃ³n estructurada
details              # JSON con informaciÃ³n adicional
nutritional_info     # JSON con datos nutricionales

# Estado del producto
in_stock             # Detectar disponibilidad
availability_text    # Texto de disponibilidad

# Campos de IA (automÃ¡ticos)
search_text          # Generado automÃ¡ticamente
embedding            # Generado por IA
embedding_model      # Modelo usado
embedding_updated_at # Timestamp de embedding

# Metadatos adicionales
last_price_update    # Timestamp de cambio de precio
scrape_count         # Contador de scrapes
```

---

## ğŸš§ COMPONENTES A DESARROLLAR

### ğŸ†• **1. Nuevos Spiders**
- `base_spider.py` - Spider base con funcionalidades comunes
- `edeka_spider.py` - Spider especÃ­fico de Edeka modernizado

### ğŸ”§ **2. Nuevos Pipelines**  
- `validation.py` - ValidaciÃ³n de datos
- `database.py` - IntegraciÃ³n con nuevos repositorios
- `enrichment.py` - Enriquecimiento de datos y parsing

### ğŸ“Š **3. Nuevos Items**
- `product_item.py` - Items compatibles con nuevos modelos

### âš™ï¸ **4. ConfiguraciÃ³n por Entornos**
- `development.py` - Config para desarrollo (lÃ­mites, delays)
- `production.py` - Config para producciÃ³n (optimizada)

### ğŸ”§ **5. Servicios de IntegraciÃ³n**
- `scraper_service.py` - Business logic para scraping
- `data_transformer.py` - TransformaciÃ³n de datos
- `price_parser.py` - Parser especializado para precios

---

## ğŸ¯ PLAN DE MIGRACIÃ“N

### ğŸ“… **Fases de ImplementaciÃ³n**

#### **Fase 1: Setup Base (30min)**
1. Crear nueva estructura en `services/scraper/`
2. Configurar entornos development/production
3. Implementar base spider class

#### **Fase 2: Data Integration (45min)**
1. Crear nuevos items compatibles
2. Implementar pipelines con nuevos repositorios  
3. Desarrollar data transformers

#### **Fase 3: Spider Modernization (30min)**
1. Migrar lÃ³gica de extracciÃ³n de edeka_spider.py
2. AÃ±adir extracciÃ³n de campos faltantes
3. Implementar mejor error handling

#### **Fase 4: Testing & Validation (30min)**
1. Testing con configuraciÃ³n de desarrollo
2. Validar integraciÃ³n con API
3. Verificar calidad de datos

### âš¡ **Configuraciones Target**

#### ğŸ§ª **Development Configuration**
```yaml
CONCURRENT_REQUESTS_PER_DOMAIN: 1
DOWNLOAD_DELAY: 3
PRODUCT_LIMIT: 50
SITEMAP_LIMIT: 2
AUTO_STOP_TIME: 300  # 5 minutes
RESPECT_ROBOTS: True
```

#### ğŸš€ **Production Configuration**  
```yaml
CONCURRENT_REQUESTS_PER_DOMAIN: 3
DOWNLOAD_DELAY: 20  # Compliance requirement
PRODUCT_LIMIT: null  # No limit
SITEMAP_LIMIT: null  # No limit
AUTO_STOP_TIME: 10800  # 3 hours
RESPECT_ROBOTS: True
SMART_THROTTLING: True
```

---

## âœ… COMPONENTES REUTILIZABLES

**Lo que podemos mantener:**
- âœ… LÃ³gica de sitemap parsing
- âœ… CSS selectors para extracciÃ³n
- âœ… Category breadcrumb extraction
- âœ… Price regex patterns (con mejoras)
- âœ… Image URL construction
- âœ… Basic error handling patterns

**Lo que debe reescribirse:**
- âŒ Pipeline completo (nuevos repositorios)
- âŒ Items definition (nuevos campos)
- âŒ Database integration (nueva arquitectura)
- âŒ Configuration management (entornos)
- âŒ Error handling y logging

---

## ğŸ‰ CONCLUSIONES

**Estado:** âœ… **MigraciÃ³n es factible y directa**

**Ventajas de la migraciÃ³n:**
- ğŸ”¥ Mejor organizaciÃ³n y mantenibilidad
- ğŸš€ IntegraciÃ³n nativa con nueva arquitectura  
- ğŸ¤– Preparado para funcionalidades de IA
- ğŸ“ˆ ConfiguraciÃ³n por entornos mÃ¡s flexible
- ğŸ›¡ï¸ Mejor error handling y monitoring

**Tiempo estimado:** ~2-2.5 horas total
**Riesgo:** ğŸŸ¢ Bajo (lÃ³gica de extracciÃ³n probada)
**Beneficio:** ğŸŸ¢ Alto (integraciÃ³n completa con nueva arquitectura)

**PrÃ³ximo paso:** Comenzar implementaciÃ³n de nueva estructura modular
