# RetailFlux - GuÃ­a de Despliegue Independiente en Dokploy

Esta guÃ­a te ayuda a desplegar cada servicio de RetailFlux de forma independiente en Dokploy, dÃ¡ndote control total sobre cada componente.

## ğŸ“‹ Prerequisitos

- Dokploy instalado y funcionando
- Dominio `api.retailflux.de` apuntando a tu servidor
- Acceso SSH al servidor
- Git repository configurado

## ğŸ—ï¸ Arquitectura de Servicios

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PostgreSQL    â”‚    â”‚       API       â”‚    â”‚    Scraper      â”‚
â”‚   Database      â”‚â—„â”€â”€â–ºâ”‚  api.retailflux â”‚    â”‚   (Scheduled)   â”‚
â”‚   Port: 5432    â”‚    â”‚   Port: 8000    â”‚    â”‚   On-demand     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                       â–²                       â–²
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Dokploy       â”‚
                    â”‚   Scheduler     â”‚
                    â”‚   (Manages      â”‚
                    â”‚   Scraper)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Orden de Despliegue

### 1. PostgreSQL Database (Primero)

#### Crear Servicio en Dokploy:
1. **Tipo**: Docker
2. **Nombre**: `retailflux-postgres`
3. **Repository**: Tu repositorio Git
4. **Dockerfile Path**: `infrastructure/standalone/postgres/Dockerfile`
5. **Build Context**: Root del proyecto

#### Variables de Entorno:
```env
POSTGRES_DB=products_db_prod
POSTGRES_USER=retailflux_user
POSTGRES_PASSWORD=TU_PASSWORD_SEGURA_AQUI
POSTGRES_HOST_AUTH_METHOD=md5
```

#### ConfiguraciÃ³n de Red:
- **Puerto interno**: 5432
- **Puerto externo**: 5432 (si necesitas acceso externo)

#### VolÃºmenes:
- `/var/lib/postgresql/data` â†’ Volumen persistente
- `/backups` â†’ Volumen para backups

---

### 2. API Service (Segundo)

#### Crear Servicio en Dokploy:
1. **Tipo**: Docker
2. **Nombre**: `retailflux-api`
3. **Repository**: Tu repositorio Git
4. **Dockerfile Path**: `infrastructure/standalone/api/Dockerfile`
5. **Build Context**: Root del proyecto

#### Variables de Entorno:
```env
APP_ENV=production
DEBUG=false
LOG_LEVEL=info

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
WORKER_PROCESSES=2

# Domain
DOMAIN=api.retailflux.de
ALLOWED_HOSTS=api.retailflux.de,localhost,127.0.0.1

# CORS
CORS_ORIGINS=https://retailflux.de,https://www.retailflux.de,https://api.retailflux.de

# Database (usar el nombre del servicio PostgreSQL)
POSTGRES_HOST=retailflux-postgres
POSTGRES_PORT=5432
POSTGRES_DB=products_db_prod
POSTGRES_USER=retailflux_user
POSTGRES_PASSWORD=LA_MISMA_PASSWORD_QUE_EN_POSTGRES

# Security
SECRET_KEY=tu_secret_key_muy_segura_aqui
JWT_SECRET_KEY=tu_jwt_secret_muy_segura_aqui

# AI (opcional)
OPENAI_API_KEY=tu_openai_key_aqui
ENABLE_AI_FEATURES=true

# Monitoring
SENTRY_DSN=tu_sentry_dsn_aqui
ENABLE_MONITORING=true
```

#### ConfiguraciÃ³n de Red:
- **Puerto interno**: 8000
- **Dominio personalizado**: `api.retailflux.de`
- **HTTPS**: Habilitado

#### Dependencias:
- Debe esperar a que PostgreSQL estÃ© saludable

---

### 3. Scraper Service (Tercero)

#### Crear Servicio en Dokploy:
1. **Tipo**: Docker
2. **Nombre**: `retailflux-scraper`
3. **Repository**: Tu repositorio Git
4. **Dockerfile Path**: `infrastructure/standalone/scraper/Dockerfile`
5. **Build Context**: Root del proyecto

#### Variables de Entorno:
```env
APP_ENV=production
DEBUG=false
LOG_LEVEL=info

# Scraper Mode (IMPORTANTE: wait para no auto-iniciar)
SCRAPER_MODE=wait
SPIDER_NAME=edeka24_spider

# Database
POSTGRES_HOST=retailflux-postgres
POSTGRES_PORT=5432
POSTGRES_DB=products_db_prod
POSTGRES_USER=retailflux_user
POSTGRES_PASSWORD=LA_MISMA_PASSWORD_QUE_EN_POSTGRES

# Scraper Settings
SCRAPER_CONCURRENT_REQUESTS=3
SCRAPER_DOWNLOAD_DELAY=1
SCRAPER_MAX_ITEMS=1000
SCRAPER_MAX_PAGES=100
SCRAPER_TEST_MODE=false

# Performance
SCRAPER_MEMORY_LIMIT=512M
SCRAPER_TIMEOUT=3600

# AI (opcional)
OPENAI_API_KEY=tu_openai_key_aqui
ENABLE_AI_FEATURES=true
```

#### ConfiguraciÃ³n de Red:
- No necesita puerto externo (funciona internamente)

#### Recursos:
- **Memoria**: 512MB - 1GB
- **CPU**: 0.5 - 1 core

---

### 4. Scheduler en Dokploy (Cuarto)

#### Crear Job/Scheduler:
1. Ve a la secciÃ³n **Jobs** o **Scheduler** en Dokploy
2. **Nombre**: `retailflux-scraper-job`
3. **Comando**: `docker exec retailflux-scraper /usr/local/bin/entrypoint.sh run`
4. **Cron Expression**: `0 */6 * * *` (cada 6 horas)
   - `0 2 * * *` = Diario a las 2 AM
   - `0 */4 * * *` = Cada 4 horas
   - `0 9,15,21 * * *` = A las 9 AM, 3 PM y 9 PM

---

## ğŸ”§ Comandos Ãštiles

### Ejecutar Scraper Manualmente:
```bash
# Ejecutar scraping normal
docker exec retailflux-scraper /usr/local/bin/entrypoint.sh run

# Ejecutar en modo test (pocos productos)
docker exec retailflux-scraper /usr/local/bin/entrypoint.sh test

# Acceder al shell del scraper
docker exec -it retailflux-scraper /usr/local/bin/entrypoint.sh shell
```

### Verificar API:
```bash
# Health check
curl https://api.retailflux.de/health

# Ver productos
curl https://api.retailflux.de/products

# Ver mÃ©tricas
curl https://api.retailflux.de/metrics
```

### Verificar Base de Datos:
```bash
# Conectar a PostgreSQL
docker exec -it retailflux-postgres psql -U retailflux_user -d products_db_prod

# Ver cantidad de productos
docker exec retailflux-postgres psql -U retailflux_user -d products_db_prod -c "SELECT COUNT(*) FROM products;"
```

---

## ğŸ” Monitoreo y Logs

### Ver Logs de Servicios:
```bash
# API logs
docker logs retailflux-api -f

# Scraper logs
docker logs retailflux-scraper -f

# PostgreSQL logs
docker logs retailflux-postgres -f
```

### Health Checks:
- **PostgreSQL**: `pg_isready` cada 30s
- **API**: `curl /health` cada 30s  
- **Scraper**: VerificaciÃ³n de conexiÃ³n DB cada 60s

---

## ğŸ› ï¸ Troubleshooting

### Si la API no es accesible desde api.retailflux.de:

1. **Verificar DNS**: 
   ```bash
   nslookup api.retailflux.de
   ```

2. **Verificar que el servicio estÃ© corriendo**:
   ```bash
   docker ps | grep retailflux-api
   ```

3. **Verificar logs de la API**:
   ```bash
   docker logs retailflux-api
   ```

4. **Verificar configuraciÃ³n de Dokploy**:
   - Dominio personalizado configurado
   - HTTPS habilitado
   - Puerto 8000 mapeado correctamente

### Si el Scraper no funciona:

1. **Verificar conexiÃ³n a base de datos**:
   ```bash
   docker exec retailflux-scraper pg_isready -h retailflux-postgres -U retailflux_user
   ```

2. **Ejecutar en modo test**:
   ```bash
   docker exec retailflux-scraper /usr/local/bin/entrypoint.sh test
   ```

3. **Ver configuraciÃ³n actual**:
   ```bash
   docker exec retailflux-scraper env | grep SCRAPER
   ```

---

## ğŸ¯ Ventajas de esta ConfiguraciÃ³n

âœ… **Servicios Independientes**: Reinicia solo lo que necesitas
âœ… **Control Granular**: Configura cada servicio por separado  
âœ… **Escalabilidad**: Escala cada servicio segÃºn necesidades
âœ… **Monitoreo**: Logs y mÃ©tricas separadas por servicio
âœ… **Mantenimiento**: Actualizaciones sin afectar otros servicios
âœ… **Debugging**: MÃ¡s fÃ¡cil identificar problemas especÃ­ficos
âœ… **Scheduler Integrado**: Control total sobre cuÃ¡ndo ejecutar scraping

---

## ğŸ“ Soporte

Si tienes problemas durante el despliegue:

1. Revisa los logs de cada servicio
2. Verifica las variables de entorno
3. Confirma que los servicios estÃ¡n saludables
4. Revisa la configuraciÃ³n de red en Dokploy

Â¡Tu RetailFlux estarÃ¡ ejecutÃ¡ndose con mÃ¡xima flexibilidad! ğŸš€