#!/usr/bin/env python3
"""
Docker entry point for running Scrapy spiders in containerized environment.
This script sets up the environment and runs the specified spider.
"""
import os
import sys
import subprocess
import time
import argparse
from pathlib import Path

def wait_for_database():
    """Wait for the database to be ready."""
    import psycopg2
    from psycopg2 import OperationalError
    
    db_config = {
        'host': os.getenv('POSTGRES_HOST', 'postgres_db'),
        'port': int(os.getenv('POSTGRES_PORT', '5432')),
        'database': os.getenv('POSTGRES_DB', 'products_db'),
        'user': os.getenv('POSTGRES_USER', 'postgres'),
        'password': os.getenv('POSTGRES_PASSWORD', 'postgres'),
    }
    
    max_retries = 30
    retry_count = 0
    
    while retry_count < max_retries:
        try:
            conn = psycopg2.connect(**db_config)
            conn.close()
            print(f"âœ… Database connection successful!")
            return True
        except OperationalError as e:
            retry_count += 1
            print(f"â³ Waiting for database... ({retry_count}/{max_retries}) - {e}")
            time.sleep(2)
    
    print("âŒ Database connection failed after maximum retries")
    return False

def run_spider(spider_name='edeka24_spider', output_file=None):
    """Run the specified spider with Scrapy."""
    
    # Change to the scraper directory
    scraper_dir = Path('/usr/src/app/services/scraper')
    os.chdir(scraper_dir)
    
    # Set environment variables
    os.environ['PYTHONPATH'] = '/usr/src/app'
    
    # Build the command
    cmd = ['python', '-m', 'scrapy', 'crawl', spider_name]
    
    if output_file:
        cmd.extend(['-o', output_file])
    
    print(f"ðŸš€ Running spider: {' '.join(cmd)}")
    print(f"ðŸ“ Working directory: {scraper_dir}")
    print(f"ðŸ Python path: {os.environ.get('PYTHONPATH')}")
    
    # Run the spider
    result = subprocess.run(cmd, capture_output=False)
    
    if result.returncode == 0:
        print("âœ… Spider completed successfully!")
    else:
        print(f"âŒ Spider failed with return code: {result.returncode}")
    
    return result.returncode

def main():
    parser = argparse.ArgumentParser(description='Run Scrapy spider in Docker')
    parser.add_argument('--spider', '-s', default='edeka24_spider', help='Spider name to run')
    parser.add_argument('--output', '-o', help='Output file for scraped data')
    parser.add_argument('--skip-db-wait', action='store_true', help='Skip waiting for database')
    
    args = parser.parse_args()
    
    print("ðŸ³ Docker Scrapy Runner Starting...")
    print(f"ðŸ“Š Spider: {args.spider}")
    if args.output:
        print(f"ðŸ“„ Output: {args.output}")
    
    # Wait for database unless skipped
    if not args.skip_db_wait:
        print("â³ Waiting for database connection...")
        if not wait_for_database():
            print("âš ï¸  Proceeding without database (will cause errors)")
    else:
        print("âš¡ Skipping database wait")
    
    # Run the spider
    exit_code = run_spider(args.spider, args.output)
    sys.exit(exit_code)

if __name__ == '__main__':
    main()
